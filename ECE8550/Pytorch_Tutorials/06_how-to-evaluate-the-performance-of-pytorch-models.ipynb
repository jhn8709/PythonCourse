{"cells": [{"cell_type": "markdown", "id": "d961ad70", "metadata": {}, "source": ["# How to Evaluate the Performance of PyTorch Models"]}, {"cell_type": "markdown", "id": "172a5131", "metadata": {}, "source": ["Designing a deep learning model is sometimes an art. \n", "There are a lot of decision points and it is not easy to tell what is the best. \n", "One way to come up with a design is by trial and error and evaluating the result on real data. \n", "Therefore, it is important to have a scientific method to evaluate the performance of your neural network and deep learning models. \n", "In fact, it is also the same method to compare any kind of machine learning models on a particular usage."]}, {"cell_type": "markdown", "id": "b3f515c8", "metadata": {}, "source": ["In this tutorial, you will discover the received work flow to robustly evaluate model performance. \n", "In the examples, we will use PyTorch to build our models, but the method can also be applied to other models."]}, {"cell_type": "markdown", "id": "6dbcbea8", "metadata": {}, "source": ["## Outcome \n", "\n", "After completing this tutorial, you will know:"]}, {"cell_type": "markdown", "id": "271dcf4b", "metadata": {}, "source": ["- How to evaluate a PyTorch model using a verification dataset\n", "- How to evaluate a PyTorch model with k-fold cross-validation"]}, {"cell_type": "markdown", "id": "9d79f98f", "metadata": {}, "source": ["## Overview"]}, {"cell_type": "markdown", "id": "c70b8ee0", "metadata": {}, "source": ["This chapter is in four parts; they are:"]}, {"cell_type": "markdown", "id": "e79a9fcd", "metadata": {}, "source": ["- Empirical Evaluation of Models\n", "- Data Splitting\n", "- Training a PyTorch Model with Validation\n", "- k-Fold Cross Validation"]}, {"cell_type": "markdown", "id": "74a76e2c", "metadata": {}, "source": ["## Empirical Evaluation of Models"]}, {"cell_type": "markdown", "id": "2e825be4", "metadata": {}, "source": ["In designing and configurating a deep learning model from scratch, there are a lot of decisions to make. \n", "This includes design decisions such as how many layers in a deep learning model, how big is each layer, and what kind of layers or activation functions to use. \n", "It can also be the choice of loss function, optimization algorithm, number of epochs to train, and the interpretation of the model output. \n", "In relief, sometimes, you can copy the structure of other people's network. \n", "Sometimes, you can just make up your choice using some heuristics. \n", "To tell if you made a good choice or not, the best is to compare multiple alternatives by empirically evaluating them with actual data."]}, {"cell_type": "markdown", "id": "da862126", "metadata": {}, "source": ["Deep learning is often used on problems that have very large datasets. \n", "That is tens of thousands or hundreds of thousands of data samples. \n", "This provides ample data for testing. \n", "But you need to have a robust test strategy to estimate the performance of your model on unseen data. \n", "Base on that, you can have a metric to compare amongst different model configurations."]}, {"cell_type": "markdown", "id": "07cfd2d9", "metadata": {}, "source": ["## Data Splitting"]}, {"cell_type": "markdown", "id": "8fa3b9f8", "metadata": {}, "source": ["If you have a dataset of tens of thousands of samples or even more, you don't always need to give everything to your model for training. \n", "This will unnecessarily increase the complexity and lengthen the training time. \n", "The more is not always better. \n", "You may not get the best result."]}, {"cell_type": "markdown", "id": "ccd8ab84", "metadata": {}, "source": ["When you get a large amount of data, usually you should take a portion of it as the training set that is feed into the model for training. \n", "Another portion is kept as test set to hold it out from training, but verified with a trained or partially trained model as evaluation. \n", "This step is usually called \"train-test split\"."]}, {"cell_type": "markdown", "id": "6fff344a", "metadata": {}, "source": ["Let's consider the Pima Indians Diabetes dataset. \n", "We can load the data using NumPy:"]}, {"cell_type": "code", "execution_count": 1, "id": "39c0c111", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "data = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")"]}, {"cell_type": "markdown", "id": "d878f651", "metadata": {}, "source": ["There are 768 data samples. \n", "It is not a lot but enough to demonstrate the split. \n", "Let's consider the first 66% as training set and the remaining as test set. \n", "The easiest way to do so is by slicing an array:"]}, {"cell_type": "code", "execution_count": 2, "id": "70d29d19", "metadata": {}, "outputs": [], "source": ["# find the boundary at 66% of total samples\n", "count = len(data)\n", "n_train = int(count * 0.66)\n", "# split the data at the boundary\n", "train_data = data[:n_train]\n", "test_data = data[n_train:]"]}, {"cell_type": "markdown", "id": "f7962f01", "metadata": {}, "source": ["The choice of 66% is arbitrary but we do not want the training set too small. \n", "Sometimes you may use 70%-30% split. \n", "But if the dataset is huge, you may even use 30%-70% split if 30% of training data is large enough."]}, {"cell_type": "markdown", "id": "1dde7f56", "metadata": {}, "source": ["If you split the data in this way, you're suggesting the data set are shuffled such that the training set and the test set are equally diverse. \n", "If you find the original dataset is sorted and you take the test set only at the end, you may find you have all the test data belong to the same class or carrying the same value in one of the input features. \n", "That's not ideal."]}, {"cell_type": "markdown", "id": "53967978", "metadata": {}, "source": ["Of course, you can call np.random.shuffle(data) before the split to avoid that. \n", "But many machine learning engineers usually use scikit-learn for this. \n", "See this example:"]}, {"cell_type": "code", "execution_count": 3, "id": "61eb3d3e", "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn.model_selection import train_test_split\n", " \n", "data = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n", "train_data, test_data = train_test_split(data, test_size=0.33)"]}, {"cell_type": "markdown", "id": "08af9c0a", "metadata": {}, "source": ["But more commonly, it is done after we separate the input feature and output labels. \n", "Note that this function from scikit-learn not only can work on NumPy arrays, but also PyTorch tensors:"]}, {"cell_type": "code", "execution_count": 4, "id": "7b272606", "metadata": {"lines_to_next_cell": 0}, "outputs": [], "source": ["import numpy as np\n", "import torch\n", "from sklearn.model_selection import train_test_split\n", " \n", "data = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n", "X = data[:, 0:8]\n", "y = data[:, 8]\n", "X = torch.tensor(X, dtype=torch.float32)\n", "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"]}, {"cell_type": "markdown", "id": "1c4fb1e2", "metadata": {}, "source": ["\n"]}, {"cell_type": "markdown", "id": "e966ddd4", "metadata": {}, "source": ["## Training a PyTorch Model with Validation"]}, {"cell_type": "markdown", "id": "17a3217c", "metadata": {}, "source": ["Let's revisit the code for building and training a deep learning model on this dataset:"]}, {"cell_type": "code", "execution_count": 7, "id": "fb26d3d8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 167.93batch/s, loss=4.16]\n", "Epoch 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 214.33batch/s, loss=3.32]\n", "Epoch 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 219.68batch/s, loss=2.54]\n", "Epoch 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 238.16batch/s, loss=1.8]\n", "Epoch 4: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 213.33batch/s, loss=1.12]\n", "Epoch 5: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 227.91batch/s, loss=0.613]\n", "Epoch 6: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 225.13batch/s, loss=0.468]\n", "Epoch 7: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 252.48batch/s, loss=0.466]\n", "Epoch 8: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 203.93batch/s, loss=0.502]\n", "Epoch 9: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 237.67batch/s, loss=0.54]\n", "Epoch 10: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 274.19batch/s, loss=0.566]\n", "Epoch 11: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 254.70batch/s, loss=0.581]\n", "Epoch 12: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 241.05batch/s, loss=0.589]\n", "Epoch 13: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 246.28batch/s, loss=0.593]\n", "Epoch 14: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 266.24batch/s, loss=0.597]\n", "Epoch 15: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 238.90batch/s, loss=0.6]\n", "Epoch 16: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 281.93batch/s, loss=0.602]\n", "Epoch 17: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 254.08batch/s, loss=0.605]\n", "Epoch 18: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 236.86batch/s, loss=0.608]\n", "Epoch 19: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 242.86batch/s, loss=0.611]\n", "Epoch 20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 261.55batch/s, loss=0.614]\n", "Epoch 21: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 258.80batch/s, loss=0.617]\n", "Epoch 22: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 255.48batch/s, loss=0.619]\n", "Epoch 23: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 247.26batch/s, loss=0.622]\n", "Epoch 24: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 257.59batch/s, loss=0.625]\n", "Epoch 25: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 257.26batch/s, loss=0.627]\n", "Epoch 26: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 269.33batch/s, loss=0.63]\n", "Epoch 27: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 288.73batch/s, loss=0.631]\n", "Epoch 28: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 244.25batch/s, loss=0.632]\n", "Epoch 29: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 267.60batch/s, loss=0.634]\n", "Epoch 30: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 254.44batch/s, loss=0.635]\n", "Epoch 31: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 260.36batch/s, loss=0.635]\n", "Epoch 32: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 240.58batch/s, loss=0.636]\n", "Epoch 33: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 281.82batch/s, loss=0.635]\n", "Epoch 34: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 236.45batch/s, loss=0.635]\n", "Epoch 35: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 254.93batch/s, loss=0.635]\n", "Epoch 36: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 249.89batch/s, loss=0.636]\n", "Epoch 37: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 241.19batch/s, loss=0.636]\n", "Epoch 38: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 253.27batch/s, loss=0.636]\n", "Epoch 39: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 231.32batch/s, loss=0.636]\n", "Epoch 40: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 252.97batch/s, loss=0.636]\n", "Epoch 41: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 248.39batch/s, loss=0.636]\n", "Epoch 42: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 178.09batch/s, loss=0.636]\n", "Epoch 43: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 223.96batch/s, loss=0.637]\n", "Epoch 44: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 235.46batch/s, loss=0.637]\n", "Epoch 45: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 242.05batch/s, loss=0.637]\n", "Epoch 46: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 220.96batch/s, loss=0.637]\n", "Epoch 47: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 223.19batch/s, loss=0.637]\n", "Epoch 48: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 256.55batch/s, loss=0.638]\n", "Epoch 49: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 255.47batch/s, loss=0.638]\n"]}], "source": ["import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import tqdm\n", "\n", "\n", "model = nn.Sequential(\n", "    nn.Linear(8, 12),\n", "    nn.ReLU(),\n", "    nn.Linear(12, 8),\n", "    nn.ReLU(),\n", "    nn.Linear(8, 1),\n", "    nn.Sigmoid()\n", ")\n", " \n", "# loss function and optimizer\n", "loss_fn = nn.BCELoss()  # binary cross entropy\n", "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n", " \n", "n_epochs = 50    # number of epochs to run\n", "batch_size = 10  # size of each batch\n", "batches_per_epoch = len(X_train) // batch_size\n", " \n", "for epoch in range(n_epochs):\n", "    with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n", "        bar.set_description(f\"Epoch {epoch}\")\n", "        for i in bar:\n", "            # take a batch\n", "            start = i * batch_size\n", "            X_batch = X_train[start:start+batch_size]\n", "            y_batch = y_train[start:start+batch_size]\n", "            # forward pass\n", "            y_pred = model(X_batch)\n", "            loss = loss_fn(y_pred, y_batch)\n", "            # backward pass\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            # update weights\n", "            optimizer.step()\n", "            # print progress\n", "            bar.set_postfix(\n", "                loss=float(loss)\n", "            )"]}, {"cell_type": "markdown", "id": "c368c2a6", "metadata": {}, "source": ["In this code, one batch is extracted from the training set in each iteration and send to the model in the forward pass. \n", "Then we compute the gradient in the backward pass and update the weights."]}, {"cell_type": "markdown", "id": "22c384c9", "metadata": {}, "source": ["While, in this case, you used binary cross entropy as the loss metric in the training loop, you may be more concerned with the prediction accuracy. \n", "Calculating accuracy is easy. \n", "You round off the output (in the range of 0 to 1) to the nearest integer so you can get a binary value of 0 or 1. \n", "Then count how much percentage your prediction matched the label is the accuracy."]}, {"cell_type": "markdown", "id": "4fcd9a0c", "metadata": {}, "source": ["But what is your prediction? It is y_pred above, which is the prediction by your current model on X_batch. \n", "Adding accuracy to the training loop becomes this:"]}, {"cell_type": "code", "execution_count": 12, "id": "003df19b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 216.98batch/s, acc=0.7, loss=0.638]\n", "Epoch 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 224.33batch/s, acc=0.7, loss=0.638]\n", "Epoch 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 224.90batch/s, acc=0.7, loss=0.638]\n", "Epoch 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 240.41batch/s, acc=0.7, loss=0.638]\n", "Epoch 4: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 246.96batch/s, acc=0.7, loss=0.638]\n", "Epoch 5: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 233.56batch/s, acc=0.7, loss=0.638]\n", "Epoch 6: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 238.23batch/s, acc=0.7, loss=0.638]\n", "Epoch 7: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 249.94batch/s, acc=0.7, loss=0.639]\n", "Epoch 8: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 248.74batch/s, acc=0.7, loss=0.638]\n", "Epoch 9: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 229.12batch/s, acc=0.7, loss=0.639]\n", "Epoch 10: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 232.26batch/s, acc=0.7, loss=0.639]\n", "Epoch 11: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 257.84batch/s, acc=0.7, loss=0.638]\n", "Epoch 12: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 249.89batch/s, acc=0.7, loss=0.639]\n", "Epoch 13: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 248.04batch/s, acc=0.7, loss=0.639]\n", "Epoch 14: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 261.91batch/s, acc=0.7, loss=0.639]\n", "Epoch 15: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 229.76batch/s, acc=0.7, loss=0.639]\n", "Epoch 16: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 240.98batch/s, acc=0.7, loss=0.639]\n", "Epoch 17: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 246.89batch/s, acc=0.7, loss=0.639]\n", "Epoch 18: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 244.69batch/s, acc=0.7, loss=0.639]\n", "Epoch 19: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 218.58batch/s, acc=0.7, loss=0.639]\n", "Epoch 20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 253.74batch/s, acc=0.7, loss=0.639]\n", "Epoch 21: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 253.72batch/s, acc=0.7, loss=0.639]\n", "Epoch 22: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 195.91batch/s, acc=0.7, loss=0.639]\n", "Epoch 23: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 223.60batch/s, acc=0.7, loss=0.639]\n", "Epoch 24: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 235.79batch/s, acc=0.7, loss=0.639]\n", "Epoch 25: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 252.85batch/s, acc=0.7, loss=0.639]\n", "Epoch 26: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 238.12batch/s, acc=0.7, loss=0.639]\n", "Epoch 27: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 233.05batch/s, acc=0.7, loss=0.639]\n", "Epoch 28: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 248.55batch/s, acc=0.7, loss=0.639]\n", "Epoch 29: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 247.74batch/s, acc=0.7, loss=0.638]\n", "Epoch 30: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 257.80batch/s, acc=0.7, loss=0.639]\n", "Epoch 31: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 194.35batch/s, acc=0.7, loss=0.639]\n", "Epoch 32: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 206.13batch/s, acc=0.7, loss=0.638]\n", "Epoch 33: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 242.02batch/s, acc=0.7, loss=0.638]\n", "Epoch 34: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 227.84batch/s, acc=0.7, loss=0.639]\n", "Epoch 35: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 229.75batch/s, acc=0.7, loss=0.638]\n", "Epoch 36: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 251.06batch/s, acc=0.7, loss=0.639]\n", "Epoch 37: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 238.42batch/s, acc=0.7, loss=0.639]\n", "Epoch 38: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 214.08batch/s, acc=0.7, loss=0.639]\n", "Epoch 39: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 213.98batch/s, acc=0.7, loss=0.639]\n", "Epoch 40: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 241.24batch/s, acc=0.7, loss=0.64]\n", "Epoch 41: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 222.54batch/s, acc=0.7, loss=0.64]\n", "Epoch 42: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 224.43batch/s, acc=0.7, loss=0.64]\n", "Epoch 43: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 247.91batch/s, acc=0.7, loss=0.64]\n", "Epoch 44: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 236.49batch/s, acc=0.7, loss=0.641]\n", "Epoch 45: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 267.09batch/s, acc=0.7, loss=0.641]\n", "Epoch 46: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 253.10batch/s, acc=0.7, loss=0.642]\n", "Epoch 47: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 256.46batch/s, acc=0.7, loss=0.642]\n", "Epoch 48: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 241.03batch/s, acc=0.7, loss=0.643]\n", "Epoch 49: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 222.66batch/s, acc=0.7, loss=0.643]\n"]}], "source": ["for epoch in range(n_epochs):\n", "    with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n", "        bar.set_description(f\"Epoch {epoch}\")\n", "        for i in bar:\n", "            # take a batch\n", "            start = i * batch_size\n", "            X_batch = X_train[start:start+batch_size]\n", "            y_batch = y_train[start:start+batch_size]\n", "            # forward pass\n", "            y_pred = model(X_batch)\n", "            loss = loss_fn(y_pred, y_batch)\n", "            # backward pass\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            # update weights\n", "            optimizer.step()\n", "            # print progress, with accuracy\n", "            acc = (y_pred.round() == y_batch).float().mean()\n", "            bar.set_postfix(loss=float(loss), acc=float(acc))"]}, {"cell_type": "markdown", "id": "8ade6065", "metadata": {}, "source": ["However, the X_batch and y_batch is used by the optimizer and the optimizer will fine tune your model to such that it can predict y_batch from X_batch. \n", "And now you're using accuracy to check if y_pred match with y_batch. \n", "It is like cheating because if your model somehow remembers the solution, it can just report to you the y_pred and get a perfect accuracy, without actually inferring y_pred from X_batch."]}, {"cell_type": "markdown", "id": "1007b914", "metadata": {}, "source": ["Indeed, a deep learning model can be so convoluted that you cannot know if your model remembers the answer or inferring the answer. \n", "Therefore the best way is not to calculate accuracy from X_batch or anything from X_train, but from something else: our test set. \n", "Let's add accuracy measurement after each epoch, using X_test:"]}, {"cell_type": "code", "execution_count": 13, "id": "24853172", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 234.28batch/s, acc=0.7, loss=0.644]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 0, accuracy 0.7322834730148315\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 238.78batch/s, acc=0.7, loss=0.644]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 1, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 261.18batch/s, acc=0.7, loss=0.645]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 2, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 266.54batch/s, acc=0.7, loss=0.647]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 3, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 4: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 258.63batch/s, acc=0.7, loss=0.648]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 4, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 5: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 254.76batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 5, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 6: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 234.65batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 6, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 7: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 256.47batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 7, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 8: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 261.61batch/s, acc=0.7, loss=0.65]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 8, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 9: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 250.02batch/s, acc=0.7, loss=0.65]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 9, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 10: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 254.48batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 10, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 11: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 257.87batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 11, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 12: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 232.50batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 12, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 13: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 246.57batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 13, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 14: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 261.16batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 14, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 15: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 258.71batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 15, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 16: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 260.25batch/s, acc=0.7, loss=0.649]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 16, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 17: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 173.63batch/s, acc=0.7, loss=0.648]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 17, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 18: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 236.79batch/s, acc=0.7, loss=0.648]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 18, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 19: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 252.78batch/s, acc=0.7, loss=0.647]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 19, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 184.16batch/s, acc=0.7, loss=0.647]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 20, accuracy 0.7204724550247192\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 21: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 208.87batch/s, acc=0.7, loss=0.647]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 21, accuracy 0.7204724550247192\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 22: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 245.09batch/s, acc=0.7, loss=0.646]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 22, accuracy 0.7204724550247192\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 23: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 236.70batch/s, acc=0.7, loss=0.646]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 23, accuracy 0.7204724550247192\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 24: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 218.96batch/s, acc=0.7, loss=0.645]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 24, accuracy 0.7204724550247192\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 25: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 220.49batch/s, acc=0.7, loss=0.645]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 25, accuracy 0.7204724550247192\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 26: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 243.01batch/s, acc=0.7, loss=0.645]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 26, accuracy 0.7204724550247192\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 27: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 215.26batch/s, acc=0.7, loss=0.644]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 27, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 28: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 213.20batch/s, acc=0.7, loss=0.644]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 28, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 29: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 238.55batch/s, acc=0.7, loss=0.644]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 29, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 30: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 228.35batch/s, acc=0.7, loss=0.644]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 30, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 31: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 200.08batch/s, acc=0.7, loss=0.643]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 31, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 32: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 213.77batch/s, acc=0.7, loss=0.643]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 32, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 33: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 264.85batch/s, acc=0.7, loss=0.643]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 33, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 34: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 238.02batch/s, acc=0.7, loss=0.642]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 34, accuracy 0.7244094610214233\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 35: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 203.85batch/s, acc=0.7, loss=0.642]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 35, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 36: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 201.51batch/s, acc=0.7, loss=0.641]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 36, accuracy 0.7322834730148315\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 37: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 187.70batch/s, acc=0.7, loss=0.641]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 37, accuracy 0.7322834730148315\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 38: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 183.15batch/s, acc=0.7, loss=0.641]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 38, accuracy 0.7322834730148315\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 39: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 205.04batch/s, acc=0.7, loss=0.641]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 39, accuracy 0.7322834730148315\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 40: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 231.43batch/s, acc=0.7, loss=0.641]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 40, accuracy 0.7322834730148315\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 41: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 222.71batch/s, acc=0.7, loss=0.64]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 41, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 42: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 214.86batch/s, acc=0.7, loss=0.64]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 42, accuracy 0.7322834730148315\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 43: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 215.72batch/s, acc=0.7, loss=0.64]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 43, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 44: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 236.85batch/s, acc=0.7, loss=0.639]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 44, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 45: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 230.76batch/s, acc=0.7, loss=0.639]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 45, accuracy 0.7322834730148315\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 46: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 221.23batch/s, acc=0.7, loss=0.639]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 46, accuracy 0.7283464670181274\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 47: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 193.60batch/s, acc=0.7, loss=0.639]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 47, accuracy 0.7362204790115356\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 48: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 234.24batch/s, acc=0.7, loss=0.638]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 48, accuracy 0.7362204790115356\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 49: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 180.64batch/s, acc=0.7, loss=0.638]"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 49, accuracy 0.7362204790115356\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n"]}], "source": ["for epoch in range(n_epochs):\n", "    with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n", "        bar.set_description(f\"Epoch {epoch}\")\n", "        for i in bar:\n", "            # take a batch\n", "            start = i * batch_size\n", "            X_batch = X_train[start:start+batch_size]\n", "            y_batch = y_train[start:start+batch_size]\n", "            # forward pass\n", "            y_pred = model(X_batch)\n", "            loss = loss_fn(y_pred, y_batch)\n", "            # backward pass\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            # update weights\n", "            optimizer.step()\n", "            # print progress\n", "            acc = (y_pred.round() == y_batch).float().mean()\n", "            bar.set_postfix(\n", "                loss=float(loss),\n", "                acc=float(acc)\n", "            )\n", "    # evaluate model at end of epoch\n", "    y_pred = model(X_test)\n", "    acc = (y_pred.round() == y_test).float().mean()\n", "    acc = float(acc)\n", "    print(f\"End of {epoch}, accuracy {acc}\")"]}, {"cell_type": "markdown", "id": "6d64551e", "metadata": {}, "source": ["In this case, the acc in the inner for-loop is just a metric showing the progress. \n", "Not much difference as displaying the loss metric except it is not involved in the gradient descent algorithm. \n", "And you expect the accuracy to improve as the loss metric also improves."]}, {"cell_type": "markdown", "id": "fc95cdfe", "metadata": {}, "source": ["In the outer for-loop, at the end of each epoch, you calculate the accuracy from X_test. \n", "The workflow is similar: You give the test set to the model and ask for its prediction, then count the number of matched result with your test set labels. \n", "But this accuracy is the one you should care about: It should improve as the training progressed, but if you do not see it improve (i.e., accuracy increase) or even deteriorates, you have to interrupt the training as it seems to start overfitting. \n", "Overfitting is when the model started to remember the training set rather than learning to infer the prediction from it. \n", "A sign of that is the accuracy from the training set keeps increasing while the accuracy from the test set is decreasing."]}, {"cell_type": "markdown", "id": "63a64541", "metadata": {}, "source": ["The following is the complete code to implement all above, from data splitting to validation using test set:"]}, {"cell_type": "code", "execution_count": 14, "id": "09d9722c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Epoch 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 262.43batch/s, acc=0.5, loss=0.888]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 0, accuracy 0.5039370059967041\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 227.89batch/s, acc=0.5, loss=0.835]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 1, accuracy 0.4881889820098877\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 228.11batch/s, acc=0.6, loss=0.798]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 2, accuracy 0.4842519760131836\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 242.48batch/s, acc=0.6, loss=0.77]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 3, accuracy 0.4803149700164795\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 4: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 229.68batch/s, acc=0.6, loss=0.75]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 4, accuracy 0.4724409580230713\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 5: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 246.54batch/s, acc=0.6, loss=0.744]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 5, accuracy 0.4685039222240448\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 6: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 235.77batch/s, acc=0.6, loss=0.744]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 6, accuracy 0.4606299102306366\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 7: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 250.52batch/s, acc=0.6, loss=0.748]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 7, accuracy 0.4685039222240448\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 8: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 245.05batch/s, acc=0.6, loss=0.752]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 8, accuracy 0.4645669162273407\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 9: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 214.50batch/s, acc=0.6, loss=0.759]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 9, accuracy 0.4763779640197754\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 10: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 223.72batch/s, acc=0.6, loss=0.768]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 10, accuracy 0.4842519760131836\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 11: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 247.74batch/s, acc=0.6, loss=0.779]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 11, accuracy 0.4842519760131836\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 12: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 246.62batch/s, acc=0.6, loss=0.793]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 12, accuracy 0.4881889820098877\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 13: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 225.34batch/s, acc=0.6, loss=0.809]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 13, accuracy 0.4960629940032959\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 14: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 242.43batch/s, acc=0.5, loss=0.828]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 14, accuracy 0.5157480239868164\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 15: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 222.59batch/s, acc=0.5, loss=0.847]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 15, accuracy 0.5236220359802246\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 16: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 224.49batch/s, acc=0.5, loss=0.864]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 16, accuracy 0.5236220359802246\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 17: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 203.69batch/s, acc=0.4, loss=0.881]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 17, accuracy 0.5236220359802246\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 18: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 243.08batch/s, acc=0.4, loss=0.896]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 18, accuracy 0.5196850299835205\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 19: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 188.09batch/s, acc=0.4, loss=0.909]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 19, accuracy 0.5275590419769287\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 20: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 204.37batch/s, acc=0.4, loss=0.918]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 20, accuracy 0.5511810779571533\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 21: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 164.11batch/s, acc=0.4, loss=0.928]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 21, accuracy 0.5629921555519104\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 22: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 160.75batch/s, acc=0.4, loss=0.937]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 22, accuracy 0.5669291615486145\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 23: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 191.39batch/s, acc=0.4, loss=0.944]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 23, accuracy 0.586614191532135\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 24: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 170.89batch/s, acc=0.4, loss=0.951]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 24, accuracy 0.5826771855354309\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 25: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 160.93batch/s, acc=0.4, loss=0.956]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 25, accuracy 0.5905511975288391\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 26: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 198.53batch/s, acc=0.4, loss=0.964]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 26, accuracy 0.5944882035255432\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 27: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 202.20batch/s, acc=0.4, loss=0.97]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 27, accuracy 0.5905511975288391\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 28: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 196.17batch/s, acc=0.4, loss=0.974]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 28, accuracy 0.6023622155189514\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 29: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 201.16batch/s, acc=0.3, loss=0.977]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 29, accuracy 0.6062992215156555\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 30: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 146.12batch/s, acc=0.3, loss=0.979]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 30, accuracy 0.6141732335090637\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 31: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 180.85batch/s, acc=0.3, loss=0.979]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 31, accuracy 0.6141732335090637\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 32: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 241.71batch/s, acc=0.3, loss=0.98]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 32, accuracy 0.6220472455024719\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 33: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 237.23batch/s, acc=0.3, loss=0.98]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 33, accuracy 0.625984251499176\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 34: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 246.90batch/s, acc=0.3, loss=0.981]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 34, accuracy 0.625984251499176\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 35: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 259.84batch/s, acc=0.3, loss=0.98]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 35, accuracy 0.625984251499176\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 36: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 249.89batch/s, acc=0.3, loss=0.979]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 36, accuracy 0.6338582634925842\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 37: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 250.30batch/s, acc=0.3, loss=0.979]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 37, accuracy 0.6338582634925842\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 38: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 251.68batch/s, acc=0.3, loss=0.977]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 38, accuracy 0.6417322754859924\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 39: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 252.06batch/s, acc=0.3, loss=0.975]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 39, accuracy 0.6456692814826965\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 40: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 255.32batch/s, acc=0.3, loss=0.973]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 40, accuracy 0.6496062874794006\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 41: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 244.94batch/s, acc=0.3, loss=0.971]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 41, accuracy 0.6496062874794006\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 42: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 209.31batch/s, acc=0.3, loss=0.968]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 42, accuracy 0.6535432934761047\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 43: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 260.30batch/s, acc=0.3, loss=0.967]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 43, accuracy 0.6535432934761047\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 44: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 264.88batch/s, acc=0.3, loss=0.966]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 44, accuracy 0.6535432934761047\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 45: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 258.53batch/s, acc=0.3, loss=0.966]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 45, accuracy 0.6614173054695129\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 46: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 247.35batch/s, acc=0.3, loss=0.965]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 46, accuracy 0.6732283234596252\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 47: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 238.20batch/s, acc=0.4, loss=0.963]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 47, accuracy 0.6692913174629211\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 48: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 248.54batch/s, acc=0.4, loss=0.961]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 48, accuracy 0.6692913174629211\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Epoch 49: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 51/51 [00:00<00:00, 233.31batch/s, acc=0.4, loss=0.96]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["End of 49, accuracy 0.6732283234596252\n"]}], "source": ["import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import tqdm\n", "from sklearn.model_selection import train_test_split\n", " \n", "data = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n", "X = data[:, 0:8]\n", "y = data[:, 8]\n", "X = torch.tensor(X, dtype=torch.float32)\n", "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n", " \n", "model = nn.Sequential(\n", "    nn.Linear(8, 12),\n", "    nn.ReLU(),\n", "    nn.Linear(12, 8),\n", "    nn.ReLU(),\n", "    nn.Linear(8, 1),\n", "    nn.Sigmoid()\n", ")\n", " \n", "# loss function and optimizer\n", "loss_fn = nn.BCELoss()  # binary cross entropy\n", "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n", " \n", "n_epochs = 50    # number of epochs to run\n", "batch_size = 10  # size of each batch\n", "batches_per_epoch = len(X_train) // batch_size\n", " \n", "for epoch in range(n_epochs):\n", "    with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar: #, disable=True) as bar:\n", "        bar.set_description(f\"Epoch {epoch}\")\n", "        for i in bar:\n", "            # take a batch\n", "            start = i * batch_size\n", "            X_batch = X_train[start:start+batch_size]\n", "            y_batch = y_train[start:start+batch_size]\n", "            # forward pass\n", "            y_pred = model(X_batch)\n", "            loss = loss_fn(y_pred, y_batch)\n", "            # backward pass\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            # update weights\n", "            optimizer.step()\n", "            # print progress\n", "            acc = (y_pred.round() == y_batch).float().mean()\n", "            bar.set_postfix(\n", "                loss=float(loss),\n", "                acc=float(acc)\n", "            )\n", "    # evaluate model at end of epoch\n", "    y_pred = model(X_test)\n", "    acc = (y_pred.round() == y_test).float().mean()\n", "    acc = float(acc)\n", "    print(f\"End of {epoch}, accuracy {acc}\")"]}, {"cell_type": "markdown", "id": "824b9b64", "metadata": {}, "source": ["## k-Fold Cross Validation"]}, {"cell_type": "markdown", "id": "a1b5a48c", "metadata": {}, "source": ["In the above example, you calculated the accuracy from the test set. \n", "It is used as a score for the model as you progressed in the training. \n", "We want to stop at the point that this score is maximum. \n", "In fact, by merely compare the score from this test set, we know our model works best after epoch 21 and start to overfit afterwards. \n", "Is that right?"]}, {"cell_type": "markdown", "id": "e8559a14", "metadata": {}, "source": ["If you built two models of different design, should you just compare these models' accuracy on the same test set and claim one is better than another?"]}, {"cell_type": "markdown", "id": "2983613c", "metadata": {}, "source": ["Actually you can argue that the test set is not representative enough even you have shuffled your dataset before extracting the test set. \n", "You may also argue that, by chance, one model fits better to this particular test set but not always better. \n", "To make a stronger argument on which model is better independent of the selection of test set, you can try with multiple test sets, and average the accuracy."]}, {"cell_type": "markdown", "id": "2d947356", "metadata": {}, "source": ["This is what a k-fold cross validation does. \n", "It is a progress to decide on which design works better. \n", "It works by repeating the training process from scratch for $k$ times, each with a different composition of the training and test set. \n", "Because of that, you will have $k$ models and $k$ accuracy scores from their respective test set. \n", "You are not only interested in the average accuracy, but also the standard deviation. \n", "The standard deviation tells whether the accuracy score is consistent or some test set is particularly good or bad to a model."]}, {"cell_type": "markdown", "id": "88b5173f", "metadata": {}, "source": ["Since k-fold cross validation is to train the model from scratch a few times, it is best to wrap around the training loop in a function:"]}, {"cell_type": "code", "execution_count": 15, "id": "3dac2f44", "metadata": {}, "outputs": [], "source": ["def model_train(X_train, y_train, X_test, y_test):\n", "    # create new model\n", "    model = nn.Sequential(\n", "        nn.Linear(8, 12),\n", "        nn.ReLU(),\n", "        nn.Linear(12, 8),\n", "        nn.ReLU(),\n", "        nn.Linear(8, 1),\n", "        nn.Sigmoid()\n", "    )\n", " \n", "    # loss function and optimizer\n", "    loss_fn = nn.BCELoss()  # binary cross entropy\n", "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n", " \n", "    n_epochs = 25    # number of epochs to run\n", "    batch_size = 10  # size of each batch\n", "    batches_per_epoch = len(X_train) // batch_size\n", " \n", "    for epoch in range(n_epochs):\n", "        with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0, disable=True) as bar:\n", "            bar.set_description(f\"Epoch {epoch}\")\n", "            for i in bar:\n", "                # take a batch\n", "                start = i * batch_size\n", "                X_batch = X_train[start:start+batch_size]\n", "                y_batch = y_train[start:start+batch_size]\n", "                # forward pass\n", "                y_pred = model(X_batch)\n", "                loss = loss_fn(y_pred, y_batch)\n", "                # backward pass\n", "                optimizer.zero_grad()\n", "                loss.backward()\n", "                # update weights\n", "                optimizer.step()\n", "                # print progress\n", "                acc = (y_pred.round() == y_batch).float().mean()\n", "                bar.set_postfix(\n", "                    loss=float(loss),\n", "                    acc=float(acc)\n", "                )\n", "    # evaluate accuracy at end of training\n", "    y_pred = model(X_test)\n", "    acc = (y_pred.round() == y_test).float().mean()\n", "    return float(acc)"]}, {"cell_type": "markdown", "id": "7e91726c", "metadata": {}, "source": ["The code above is deliberately not print anything (with disable=True in tqdm) to keep the screen less cluttered."]}, {"cell_type": "markdown", "id": "bb3bc9c8", "metadata": {}, "source": ["Also from scikit-learn, we have a function for k-fold cross validation. \n", "We can make use of it to produce a robust estimate of model accuracy:"]}, {"cell_type": "code", "execution_count": 16, "id": "f19bc152", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Accuracy: 0.65\n", "Accuracy: 0.66\n", "Accuracy: 0.68\n", "Accuracy: 0.65\n", "Accuracy: 0.65\n", "65.62% (+/- 1.32%)\n"]}], "source": ["from sklearn.model_selection import StratifiedKFold\n", " \n", "# define 5-fold cross validation test harness\n", "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n", "cv_scores = []\n", "for train, test in kfold.split(X, y):\n", "    # create model, train, and get accuracy\n", "    acc = model_train(X[train], y[train], X[test], y[test])\n", "    print(\"Accuracy: %.2f\" % acc)\n", "    cv_scores.append(acc)\n", "# evaluate the model\n", "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores)*100, np.std(cv_scores)*100))"]}, {"cell_type": "markdown", "id": "db913002", "metadata": {}, "source": ["In scikit-learn, there are multiple k-fold cross validation functions and the one used here is stratified k-fold. \n", "It assumes y are class labels and takes into account of their values such that it will provide a balanced class representation in the splits."]}, {"cell_type": "markdown", "id": "e5158b4e", "metadata": {}, "source": ["The code above used $k=5$ or 5 splits. \n", "It means to split the dataset into 5 equal portions and pick one of them as test set while the rest is combined into a training set. \n", "There are 5 ways of doing that so the for-loop above will have 5 iterations. \n", "In each iteration, you called the model_train() function and obtained the accuracy score in return. \n", "Then you save it into a list, which will be used to calculate the mean and standard deviation at the end."]}, {"cell_type": "markdown", "id": "2e0e98b6", "metadata": {}, "source": ["The kfold object will return to you the indices. \n", "Hence you do not need to run train-test split in advance but to use the indices provided to extract the training set and test set on the fly when you call the model_train() function."]}, {"cell_type": "markdown", "id": "e257f289", "metadata": {}, "source": ["The result above shows the model is moderately good, at 64% average accuracy. \n", "And this score is stable since the standard deviation is at 3% level, which means for most of the time, we expects the model accuracy to be 61% to 67%. \n", "You may try to change the model above, such as adding or removing a layer, and see how much change you have in the mean and standard deviation. \n", "You may also try to increase the number of epoch in training and observe the result."]}, {"cell_type": "markdown", "id": "a3597c02", "metadata": {}, "source": ["The mean and standard deviation from the k-fold cross validation is the way you should use to benchmark a model design."]}, {"cell_type": "markdown", "id": "c9d11b5a", "metadata": {}, "source": ["Tying all together, below is the complete code for k-fold cross validation:"]}, {"cell_type": "code", "execution_count": 17, "id": "1ebb4303", "metadata": {"lines_to_next_cell": 0}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Accuracy: 0.67\n", "Accuracy: 0.73\n", "Accuracy: 0.61\n", "Accuracy: 0.67\n", "Accuracy: 0.65\n", "66.67% (+/- 3.76%)\n"]}], "source": ["import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import tqdm\n", "from sklearn.model_selection import StratifiedKFold\n", " \n", "data = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n", "X = data[:, 0:8]\n", "y = data[:, 8]\n", "X = torch.tensor(X, dtype=torch.float32)\n", "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n", " \n", "def model_train(X_train, y_train, X_test, y_test):\n", "    # create new model\n", "    model = nn.Sequential(\n", "        nn.Linear(8, 12),\n", "        nn.ReLU(),\n", "        nn.Linear(12, 8),\n", "        nn.ReLU(),\n", "        nn.Linear(8, 1),\n", "        nn.Sigmoid()\n", "    )\n", " \n", "    # loss function and optimizer\n", "    loss_fn = nn.BCELoss()  # binary cross entropy\n", "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n", " \n", "    n_epochs = 25    # number of epochs to run\n", "    batch_size = 10  # size of each batch\n", "    batches_per_epoch = len(X_train) // batch_size\n", " \n", "    for epoch in range(n_epochs):\n", "        with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0, disable=True) as bar:\n", "            bar.set_description(f\"Epoch {epoch}\")\n", "            for i in bar:\n", "                # take a batch\n", "                start = i * batch_size\n", "                X_batch = X_train[start:start+batch_size]\n", "                y_batch = y_train[start:start+batch_size]\n", "                # forward pass\n", "                y_pred = model(X_batch)\n", "                loss = loss_fn(y_pred, y_batch)\n", "                # backward pass\n", "                optimizer.zero_grad()\n", "                loss.backward()\n", "                # update weights\n", "                optimizer.step()\n", "                # print progress\n", "                acc = (y_pred.round() == y_batch).float().mean()\n", "                bar.set_postfix(\n", "                    loss=float(loss),\n", "                    acc=float(acc)\n", "                )\n", "    # evaluate accuracy at end of training\n", "    y_pred = model(X_test)\n", "    acc = (y_pred.round() == y_test).float().mean()\n", "    return float(acc)\n", " \n", "# define 5-fold cross validation test harness\n", "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n", "cv_scores = []\n", "for train, test in kfold.split(X, y):\n", "    # create model, train, and get accuracy\n", "    acc = model_train(X[train], y[train], X[test], y[test])\n", "    print(\"Accuracy: %.2f\" % acc)\n", "    cv_scores.append(acc)\n", "# evaluate the model\n", "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cv_scores)*100, np.std(cv_scores)*100))"]}, {"cell_type": "markdown", "id": "5882fc13", "metadata": {}, "source": ["## Summary"]}, {"cell_type": "markdown", "id": "d8bca913", "metadata": {}, "source": ["In this tutorial, you discovered the importance of having a robust way to estimate the performance of your deep learning models on unseen data and you learned how to do that. \n", "You saw:"]}, {"cell_type": "markdown", "id": "bdf1705b", "metadata": {}, "source": ["- How to split data into training and test set using scikit-learn\n", "- How to do k-fold cross validation with the help of scikit-learn\n", "- How to modify the training loop in a PyTorch model to incorporate test set validation and cross validation"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.13"}}, "nbformat": 4, "nbformat_minor": 5}